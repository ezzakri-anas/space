{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c27dd8e7-8be9-450e-a390-16b79312453f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.2.7-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /home/aezzakri/.local/lib/python3.10/site-packages (from ultralytics) (3.8.4)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/aezzakri/.local/lib/python3.10/site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/lib/python3/dist-packages (from ultralytics) (5.4.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/lib/python3/dist-packages (from ultralytics) (2.25.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/aezzakri/.local/lib/python3.10/site-packages (from ultralytics) (1.13.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/aezzakri/.local/lib/python3.10/site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/aezzakri/.local/lib/python3.10/site-packages (from ultralytics) (0.17.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/aezzakri/.local/lib/python3.10/site-packages (from ultralytics) (4.66.2)\n",
      "Requirement already satisfied: psutil in /home/aezzakri/.local/lib/python3.10/site-packages (from ultralytics) (5.9.8)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting thop>=0.1.1 (from ultralytics)\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting pandas>=1.1.4 (from ultralytics)\n",
      "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/aezzakri/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/aezzakri/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/aezzakri/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/aezzakri/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/aezzakri/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/aezzakri/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/aezzakri/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.1.4->ultralytics)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.1.4->ultralytics)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch>=1.8.0->ultralytics) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/aezzakri/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/aezzakri/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: six>=1.5 in /home/aezzakri/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/aezzakri/.local/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.2.7-py3-none-any.whl (755 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m755.1/755.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, py-cpuinfo, tzdata, opencv-python, pandas, seaborn, thop, ultralytics\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2018.9\n",
      "    Uninstalling pytz-2018.9:\n",
      "      Successfully uninstalled pytz-2018.9\n",
      "Successfully installed opencv-python-4.9.0.80 pandas-2.2.2 py-cpuinfo-9.0.0 pytz-2024.1 seaborn-0.13.2 thop-0.1.1.post2209072238 tzdata-2024.1 ultralytics-8.2.7\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n",
      "Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.9.0.80\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wandb in /home/aezzakri/.local/lib/python3.10/site-packages (0.16.6)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/lib/python3/dist-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/aezzakri/.local/lib/python3.10/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/lib/python3/dist-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/aezzakri/.local/lib/python3.10/site-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/aezzakri/.local/lib/python3.10/site-packages (from wandb) (1.45.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/aezzakri/.local/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: setproctitle in /home/aezzakri/.local/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb) (59.6.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/aezzakri/.local/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/aezzakri/.local/lib/python3.10/site-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/aezzakri/.local/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/aezzakri/.local/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: certifi in /home/aezzakri/.local/lib/python3.10/site-packages (from sentry-sdk>=1.0.0->wandb) (2019.3.9)\n",
      "Requirement already satisfied: urllib3>=1.26.11 in /home/aezzakri/.local/lib/python3.10/site-packages (from sentry-sdk>=1.0.0->wandb) (2.2.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/aezzakri/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "!pip install opencv-python-headless\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e48218c-dcda-4701-8647-625d3be3930c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/aezzakri/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m This integration is tested and supported for ultralytics v8.0.238 and below.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m             Please report any issues to https://github.com/wandb/wandb/issues with the tag `yolov8`.\n"
     ]
    }
   ],
   "source": [
    "# Visualisation\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from matplotlib.pyplot import figure\n",
    "from PIL import Image\n",
    "\n",
    "# Model Building\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from wandb.integration.ultralytics import add_wandb_callback\n",
    "import wandb\n",
    "# import labelme2yolo\n",
    "\n",
    "# Others\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8d131e-b784-49ec-b2dc-d8395063d22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ade6c74b-dc8f-4b09-a4f7-372cdfd27905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mezzakrianas65\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aezzakri/Dvlp/py_test/drivdata/notebook/wandb/run-20240503_171339-ea7b4s6q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ezzakrianas65/PP_yolo/runs/ea7b4s6q' target=\"_blank\">rare-moon-4</a></strong> to <a href='https://wandb.ai/ezzakrianas65/PP_yolo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ezzakrianas65/PP_yolo' target=\"_blank\">https://wandb.ai/ezzakrianas65/PP_yolo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ezzakrianas65/PP_yolo/runs/ea7b4s6q' target=\"_blank\">https://wandb.ai/ezzakrianas65/PP_yolo/runs/ea7b4s6q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ezzakrianas65/PP_yolo/runs/ea7b4s6q?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7e3d08eb4d30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"PP_yolo\", job_type=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c55eb9b4-e0ce-4e64-8347-a9f494438fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:01<00:00, 4.12MB/s]\n"
     ]
    }
   ],
   "source": [
    "#Loading the model\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0ea863-cd8d-46f3-930e-240d1744223d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (11): Concat()\n",
       "      (12): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (14): Concat()\n",
       "      (15): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (17): Concat()\n",
       "      (18): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (20): Concat()\n",
       "      (21): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_wandb_callback(model, enable_model_checkpointing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51703c1-2013-4d01-a777-f509406d7eb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.6 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.5 ðŸš€ Python-3.11.8 torch-2.1.2.post300 CUDA:0 (Tesla T4, 15948MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=datasets/dataset.yaml, epochs=500, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=Results/, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=Results/train2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/jovyan/datasets/labels/train.cache... 4758 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4758/4758 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jovyan/datasets/labels/train.cache... 4758 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4758/4758 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to Results/train2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mResults/train2\u001b[0m\n",
      "Starting training for 500 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/500      2.29G      1.244      2.659      1.197         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:51<00:00,  5.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:56<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.739      0.655      0.698      0.483\n",
      "Ultralytics YOLOv8.2.5 ðŸš€ Python-3.11.8 torch-2.1.2.post300 CUDA:0 (Tesla T4, 15948MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8748c1336249cfb240abab770c1026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15b838bd6004ee78e32dd4ede3b6502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/500      2.37G      1.266      1.757      1.224         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.749      0.599      0.681      0.456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0537f9f855d4455b4572534c8385071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895eb03299c94e5fa0d8713e04b17eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/500      2.36G      1.403      1.573      1.303         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.688      0.561       0.61       0.37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f18406a7a0c4e27bf9554c20182762c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464eeea249334a78900f7c16836fa8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/500      2.34G      1.521      1.566      1.382          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.708      0.607      0.658      0.405\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102d0a90329b47c0bd061def02cd8e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23bcf66a00594bf9bb195c4661156fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/500      2.33G      1.455      1.455      1.351         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.787      0.659       0.73      0.468\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98fb1f8f1bbb4809b22a0a50cb1eb592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ae47bb7fd64991a50520e4adf2e400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/500      2.33G      1.446        1.4      1.339         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.785      0.685      0.757      0.505\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accedc31fb3547528d94cf5bf25ef207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b0ad5585ca4059aaf4ecc2e89f8ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/500      2.33G      1.378      1.338      1.316         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.817      0.708      0.779      0.516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839cb021aa6b4f419b961a6c41d2e256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6a6af3e3134f8b8592a362a7831e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/500      2.32G      1.317      1.256      1.288          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:51<00:00,  5.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.835      0.721      0.797       0.55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6a7e0b47c4499397027cca11db22dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e751d98d164150ad1044c3d7d9186e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/500      2.32G      1.282      1.196      1.263         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.832      0.723      0.802      0.561\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f76223b5c0d4d7da81ce0c8b4d1241d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf1d69fb8e949d3a216ff2d4e68801b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/500      2.32G      1.275      1.185      1.265          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:49<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.854      0.741      0.821      0.576\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96d1e06f49c45fba0ec640e47ba706e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1b602ab05c4871a218b154e761d636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/500      2.32G      1.245      1.167      1.244          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758       0.84      0.775      0.822      0.556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510cb2d9d8314261b842f37efe0a2f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e768bc4308744da6a7f1281152ae2930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/500      2.32G      1.235      1.137       1.25          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.869      0.755      0.841      0.606\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400750b29fa24b1e80a87acbeeebc733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74dd781307aa4ac297d77d630531dca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/500      2.32G      1.217      1.127       1.25         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.851      0.765      0.847      0.609\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acae12782e9a460cbb194fc4d49b3049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafa4fd4d4ea4f23afd5d4a84c866007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/500      2.32G      1.196      1.084       1.23         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.887      0.787      0.864      0.618\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf7ff7c7a024b518acd73439ab15a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54d0408e67a434994fb76cac2a301a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/500      2.32G      1.175      1.073      1.231         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.878      0.795      0.861      0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a128b2cd8442b2a1b9da23df8c75a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b22ff2dcbb4380bef4b1eb99aeccc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed58dfe598c441d19c016f20e2d5d0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/500      2.32G      1.113      1.005      1.191         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:49<00:00,  5.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.896      0.792      0.874      0.646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca568039ea9240bb98ccddfe2bdbb7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb9543015f747f69c19cec974831b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/500      2.32G      1.108     0.9754      1.181         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.895      0.817      0.886      0.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a869b526ac2e48b48027898bcd6e9120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36587eaa29084bc784ce100dd75cd676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/500      2.32G      1.084     0.9633      1.176         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.898      0.803       0.88      0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331ed5516e4b42fab37443b10da76c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea376bb91214943894cb1683610f4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/500      2.32G      1.081      0.967      1.168          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.897      0.806      0.886      0.666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e46373124f043b685790a735a019673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb062f927df44d48c0e6528d4e32c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/500      2.32G      1.074     0.9691      1.157         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:51<00:00,  5.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.894      0.807      0.884      0.659\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7279485d6a49eb8535db51f4aeb48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f7d36500274ba0b3a16aaefdca712c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/500      2.32G      1.079     0.9582      1.165         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.897      0.811      0.885      0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1079abcbc74c1aa50b1882cd710153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4b677277ad411e9f2393c2868c2103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/500      2.32G      1.078     0.9609      1.167          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.914      0.823      0.895       0.68\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3b2f7db79f42e69f5830dcd71357ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8eacc4be02a47048ad3371e2738dcdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/500      2.32G      1.065     0.9449      1.167         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:51<00:00,  5.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.904      0.816      0.893      0.682\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3aa705fc8e4ecab9394466e18df22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590f69f9943147cbaae6a2f83b05cc81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/500      2.32G      1.054     0.9194      1.142          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.911      0.831      0.903      0.695\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d594ce1c169a43e7a51062a07c767c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493a4fd4e5da4d5e8f264160c7c141e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/500      2.32G      1.054     0.9286      1.155         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:51<00:00,  5.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.914      0.827      0.902      0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe33a00f8164e00977b53e1580d6ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00870077cab47d8a3bd28ed1ae4e9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/500      2.32G      1.039     0.9124      1.144         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:51<00:00,  5.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.911      0.826      0.904      0.693\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4a4b7213784a149bcf251ef911c65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcc3293d25f4219914ed24e644bb927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/500      2.32G      1.045     0.9165      1.154         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:51<00:00,  5.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.902      0.821      0.895      0.684\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063f30f22ceb41c8aa0c05f57b02667e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9492bf46503442d5a1f543792f8de88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/500      2.32G      1.042      0.913      1.142          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.905      0.827      0.899      0.694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282e12645503452e9e5450581da63974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165118d4883c49bf945d3ba4cab99cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/500      2.32G      1.017     0.8801      1.133          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758       0.92      0.832      0.907        0.7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d3d90d09be43b692b582d96e537816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76e0a5358b544838bf2f46ca90f6443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/500      2.32G      1.018      0.887      1.135          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.921      0.832      0.908      0.706\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720bab99c3114c1699cd306d837721fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccea7748480742e99dbb1d9ce3da0d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/500      2.32G      1.015     0.8809      1.132         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.907      0.843      0.906      0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51a184b4980463595490ade056ed1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c693d8b9e61a47b0bcce44d9c1f0a19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/500      2.32G      1.031     0.9089      1.139         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.918      0.831       0.91      0.711\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12994244907436582c0487dc389d08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e654eff34741f4a22bd98d0cc3167c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/500      2.32G      0.995     0.8543      1.115         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.902      0.833      0.905      0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a996a9dc48144a4bcc4e3769cf1ed87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226502af8ac64df08b8ce44a471e678d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/500      2.32G      1.006     0.8734      1.118         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:51<00:00,  5.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.907      0.858      0.916      0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a4992e24d74ac4bdb790d1e2670d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae0cc2b301646aa9cbf6e9a76970460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/500      2.32G       1.01     0.8831      1.125         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758       0.91      0.842      0.912      0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1035f72b864cb5ad10590b031b1e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6386f89a2504f23ae0f1badfab8f368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/500      2.32G     0.9946     0.8713      1.132         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:51<00:00,  5.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:37<00:00,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.908      0.833      0.906      0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e24aff8071457eae23f0ecc3210000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e40b12083c42debb8416e50e04a3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/500      2.32G     0.9879     0.8423      1.113         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.926       0.83      0.914      0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e10a20d5a841cd96c36c8a5d44150d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4fc1ce1c2a4ac4a32a71cd066079fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/500      2.32G     0.9979     0.8613      1.117          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:38<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4758       4758      0.915      0.841      0.917      0.718\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37aae5225d9c483d9960e0805ce70308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7af95a1686b481b95a8a228f8713e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/500      2.32G     0.9831      0.842      1.113          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298/298 [00:50<00:00,  5.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  24%|â–ˆâ–ˆâ–       | 36/149 [00:08<00:26,  4.21it/s]"
     ]
    }
   ],
   "source": [
    "results = model.train(data='datasets/dataset.yaml', epochs=500, imgsz=640, project='Results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71cd371-14b1-4b2e-a5a1-f679f9165530",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9bd420-b369-422e-835b-30e5cf634aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(15, 10), dpi=80)\n",
    "# reading the image\n",
    "# results = img.imread('drive/MyDrive/YOLOv8_Results_BRRA/train/results.csv')\n",
    "ultralytics.utils.plotting.plot_results(file='drive/MyDrive/YOLOv8_Results_BRRA/train3/results.csv')\n",
    "# displaying the image\n",
    "# plt.imshow(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba896b44-9140-4b35-aa99-7d6f750eb961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /srv/conda/envs/notebook/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.4.28-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /srv/conda/envs/notebook/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.4.28-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m785.2/785.2 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.4.28 tokenizers-0.19.1 transformers-4.40.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fadde31e-a150-40d4-a8c4-1bac56d7a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1adda1dd-8a92-4d53-8c45-67eb3d44dd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-01 13:28:36--  https://github.com/Houda222/competition/blob/main/toYolo.ipynb\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: â€˜toYolo.ipynbâ€™\n",
      "\n",
      "toYolo.ipynb            [ <=>                ] 149.91K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2024-05-01 13:28:36 (4.80 MB/s) - â€˜toYolo.ipynbâ€™ saved [153512]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/Houda222/competition/blob/main/toYolo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05909669-2426-4aae-889c-9022a911d9db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "923291a2-2e0e-4792-8edc-a21cf2854e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method from_pretrained in module transformers.modeling_utils:\n",
      "\n",
      "from_pretrained(pretrained_model_name_or_path: Union[str, os.PathLike, NoneType], *model_args, config: Union[transformers.configuration_utils.PretrainedConfig, str, os.PathLike, NoneType] = None, cache_dir: Union[str, os.PathLike, NoneType] = None, ignore_mismatched_sizes: bool = False, force_download: bool = False, local_files_only: bool = False, token: Union[bool, str, NoneType] = None, revision: str = 'main', use_safetensors: bool = None, **kwargs) method of builtins.type instance\n",
      "    Instantiate a pretrained pytorch model from a pre-trained model configuration.\n",
      "    \n",
      "    The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated). To train\n",
      "    the model, you should first set it back in training mode with `model.train()`.\n",
      "    \n",
      "    The warning *Weights from XXX not initialized from pretrained model* means that the weights of XXX do not come\n",
      "    pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning\n",
      "    task.\n",
      "    \n",
      "    The warning *Weights from XXX not used in YYY* means that the layer XXX is not used by YYY, therefore those\n",
      "    weights are discarded.\n",
      "    \n",
      "    Parameters:\n",
      "        pretrained_model_name_or_path (`str` or `os.PathLike`, *optional*):\n",
      "            Can be either:\n",
      "    \n",
      "                - A string, the *model id* of a pretrained model hosted inside a model repo on huggingface.co.\n",
      "                - A path to a *directory* containing model weights saved using\n",
      "                  [`~PreTrainedModel.save_pretrained`], e.g., `./my_model_directory/`.\n",
      "                - A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`). In\n",
      "                  this case, `from_tf` should be set to `True` and a configuration object should be provided as\n",
      "                  `config` argument. This loading path is slower than converting the TensorFlow checkpoint in a\n",
      "                  PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n",
      "                - A path or url to a model folder containing a *flax checkpoint file* in *.msgpack* format (e.g,\n",
      "                  `./flax_model/` containing `flax_model.msgpack`). In this case, `from_flax` should be set to\n",
      "                  `True`.\n",
      "                - `None` if you are both providing the configuration and state dictionary (resp. with keyword\n",
      "                  arguments `config` and `state_dict`).\n",
      "        model_args (sequence of positional arguments, *optional*):\n",
      "            All remaining positional arguments will be passed to the underlying model's `__init__` method.\n",
      "        config (`Union[PretrainedConfig, str, os.PathLike]`, *optional*):\n",
      "            Can be either:\n",
      "    \n",
      "                - an instance of a class derived from [`PretrainedConfig`],\n",
      "                - a string or path valid as input to [`~PretrainedConfig.from_pretrained`].\n",
      "    \n",
      "            Configuration for the model to use instead of an automatically loaded configuration. Configuration can\n",
      "            be automatically loaded when:\n",
      "    \n",
      "                - The model is a model provided by the library (loaded with the *model id* string of a pretrained\n",
      "                  model).\n",
      "                - The model was saved using [`~PreTrainedModel.save_pretrained`] and is reloaded by supplying the\n",
      "                  save directory.\n",
      "                - The model is loaded by supplying a local directory as `pretrained_model_name_or_path` and a\n",
      "                  configuration JSON file named *config.json* is found in the directory.\n",
      "        state_dict (`Dict[str, torch.Tensor]`, *optional*):\n",
      "            A state dictionary to use instead of a state dictionary loaded from saved weights file.\n",
      "    \n",
      "            This option can be used if you want to create a model from a pretrained configuration but load your own\n",
      "            weights. In this case though, you should check if using [`~PreTrainedModel.save_pretrained`] and\n",
      "            [`~PreTrainedModel.from_pretrained`] is not a simpler option.\n",
      "        cache_dir (`Union[str, os.PathLike]`, *optional*):\n",
      "            Path to a directory in which a downloaded pretrained model configuration should be cached if the\n",
      "            standard cache should not be used.\n",
      "        from_tf (`bool`, *optional*, defaults to `False`):\n",
      "            Load the model weights from a TensorFlow checkpoint save file (see docstring of\n",
      "            `pretrained_model_name_or_path` argument).\n",
      "        from_flax (`bool`, *optional*, defaults to `False`):\n",
      "            Load the model weights from a Flax checkpoint save file (see docstring of\n",
      "            `pretrained_model_name_or_path` argument).\n",
      "        ignore_mismatched_sizes (`bool`, *optional*, defaults to `False`):\n",
      "            Whether or not to raise an error if some of the weights from the checkpoint do not have the same size\n",
      "            as the weights of the model (if for instance, you are instantiating a model with 10 labels from a\n",
      "            checkpoint with 3 labels).\n",
      "        force_download (`bool`, *optional*, defaults to `False`):\n",
      "            Whether or not to force the (re-)download of the model weights and configuration files, overriding the\n",
      "            cached versions if they exist.\n",
      "        resume_download (`bool`, *optional*, defaults to `False`):\n",
      "            Whether or not to delete incompletely received files. Will attempt to resume the download if such a\n",
      "            file exists.\n",
      "        proxies (`Dict[str, str]`, *optional*):\n",
      "            A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128',\n",
      "            'http://hostname': 'foo.bar:4012'}`. The proxies are used on each request.\n",
      "        output_loading_info(`bool`, *optional*, defaults to `False`):\n",
      "            Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.\n",
      "        local_files_only(`bool`, *optional*, defaults to `False`):\n",
      "            Whether or not to only look at local files (i.e., do not try to download the model).\n",
      "        token (`str` or `bool`, *optional*):\n",
      "            The token to use as HTTP bearer authorization for remote files. If `True`, or not specified, will use\n",
      "            the token generated when running `huggingface-cli login` (stored in `~/.huggingface`).\n",
      "        revision (`str`, *optional*, defaults to `\"main\"`):\n",
      "            The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n",
      "            git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\n",
      "            identifier allowed by git.\n",
      "    \n",
      "            <Tip>\n",
      "    \n",
      "            To test a pull request you made on the Hub, you can pass `revision=\"refs/pr/<pr_number>\".\n",
      "    \n",
      "            </Tip>\n",
      "    \n",
      "        mirror (`str`, *optional*):\n",
      "            Mirror source to accelerate downloads in China. If you are from China and have an accessibility\n",
      "            problem, you can set this option to resolve it. Note that we do not guarantee the timeliness or safety.\n",
      "            Please refer to the mirror site for more information.\n",
      "        _fast_init(`bool`, *optional*, defaults to `True`):\n",
      "            Whether or not to disable fast initialization.\n",
      "    \n",
      "            <Tip warning={true}>\n",
      "    \n",
      "            One should only disable *_fast_init* to ensure backwards compatibility with `transformers.__version__ <\n",
      "            4.6.0` for seeded model initialization. This argument will be removed at the next major version. See\n",
      "            [pull request 11471](https://github.com/huggingface/transformers/pull/11471) for more information.\n",
      "    \n",
      "            </Tip>\n",
      "        attn_implementation (`str`, *optional*):\n",
      "            The attention implementation to use in the model (if relevant). Can be any of `\"eager\"` (manual implementation of the attention), `\"sdpa\"` (using [`F.scaled_dot_product_attention`](https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention.html)), or `\"flash_attention_2\"` (using [Dao-AILab/flash-attention](https://github.com/Dao-AILab/flash-attention)). By default, if available, SDPA will be used for torch>=2.1.1. The default is otherwise the manual `\"eager\"` implementation.\n",
      "    \n",
      "        > Parameters for big model inference\n",
      "    \n",
      "        low_cpu_mem_usage(`bool`, *optional*):\n",
      "            Tries to not use more than 1x model size in CPU memory (including peak memory) while loading the model.\n",
      "            This is an experimental feature and a subject to change at any moment.\n",
      "        torch_dtype (`str` or `torch.dtype`, *optional*):\n",
      "            Override the default `torch.dtype` and load the model under a specific `dtype`. The different options\n",
      "            are:\n",
      "    \n",
      "            1. `torch.float16` or `torch.bfloat16` or `torch.float`: load in a specified\n",
      "              `dtype`, ignoring the model's `config.torch_dtype` if one exists. If not specified\n",
      "              - the model will get loaded in `torch.float` (fp32).\n",
      "    \n",
      "            2. `\"auto\"` - A `torch_dtype` entry in the `config.json` file of the model will be\n",
      "              attempted to be used. If this entry isn't found then next check the `dtype` of the first weight in\n",
      "              the checkpoint that's of a floating point type and use that as `dtype`. This will load the model\n",
      "              using the `dtype` it was saved in at the end of the training. It can't be used as an indicator of how\n",
      "              the model was trained. Since it could be trained in one of half precision dtypes, but saved in fp32.\n",
      "    \n",
      "            <Tip>\n",
      "    \n",
      "            For some models the `dtype` they were trained in is unknown - you may try to check the model's paper or\n",
      "            reach out to the authors and ask them to add this information to the model's card and to insert the\n",
      "            `torch_dtype` entry in `config.json` on the hub.\n",
      "    \n",
      "            </Tip>\n",
      "    \n",
      "        device_map (`str` or `Dict[str, Union[int, str, torch.device]]` or `int` or `torch.device`, *optional*):\n",
      "            A map that specifies where each submodule should go. It doesn't need to be refined to each\n",
      "            parameter/buffer name, once a given module name is inside, every submodule of it will be sent to the\n",
      "            same device. If we only pass the device (*e.g.*, `\"cpu\"`, `\"cuda:1\"`, `\"mps\"`, or a GPU ordinal rank\n",
      "            like `1`) on which the model will be allocated, the device map will map the entire model to this\n",
      "            device. Passing `device_map = 0` means put the whole model on GPU 0.\n",
      "    \n",
      "            To have Accelerate compute the most optimized `device_map` automatically, set `device_map=\"auto\"`. For\n",
      "            more information about each option see [designing a device\n",
      "            map](https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map).\n",
      "        max_memory (`Dict`, *optional*):\n",
      "            A dictionary device identifier to maximum memory. Will default to the maximum memory available for each\n",
      "            GPU and the available CPU RAM if unset.\n",
      "        offload_folder (`str` or `os.PathLike`, *optional*):\n",
      "            If the `device_map` contains any value `\"disk\"`, the folder where we will offload weights.\n",
      "        offload_state_dict (`bool`, *optional*):\n",
      "            If `True`, will temporarily offload the CPU state dict to the hard drive to avoid getting out of CPU\n",
      "            RAM if the weight of the CPU state dict + the biggest shard of the checkpoint does not fit. Defaults to\n",
      "            `True` when there is some disk offload.\n",
      "        offload_buffers (`bool`, *optional*):\n",
      "            Whether or not to offload the buffers with the model parameters.\n",
      "        quantization_config (`Union[QuantizationConfigMixin,Dict]`, *optional*):\n",
      "            A dictionary of configuration parameters or a QuantizationConfigMixin object for quantization (e.g\n",
      "            bitsandbytes, gptq). There may be other quantization-related kwargs, including `load_in_4bit` and\n",
      "            `load_in_8bit`, which are parsed by QuantizationConfigParser. Supported only for bitsandbytes\n",
      "            quantizations and not preferred. consider inserting all such arguments into quantization_config\n",
      "            instead.\n",
      "        subfolder (`str`, *optional*, defaults to `\"\"`):\n",
      "            In case the relevant files are located inside a subfolder of the model repo on huggingface.co, you can\n",
      "            specify the folder name here.\n",
      "        variant (`str`, *optional*):\n",
      "            If specified load weights from `variant` filename, *e.g.* pytorch_model.<variant>.bin. `variant` is\n",
      "            ignored when using `from_tf` or `from_flax`.\n",
      "        use_safetensors (`bool`, *optional*, defaults to `None`):\n",
      "            Whether or not to use `safetensors` checkpoints. Defaults to `None`. If not specified and `safetensors`\n",
      "            is not installed, it will be set to `False`.\n",
      "    \n",
      "        kwargs (remaining dictionary of keyword arguments, *optional*):\n",
      "            Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,\n",
      "            `output_attentions=True`). Behaves differently depending on whether a `config` is provided or\n",
      "            automatically loaded:\n",
      "    \n",
      "                - If a configuration is provided with `config`, `**kwargs` will be directly passed to the\n",
      "                  underlying model's `__init__` method (we assume all relevant updates to the configuration have\n",
      "                  already been done)\n",
      "                - If a configuration is not provided, `kwargs` will be first passed to the configuration class\n",
      "                  initialization function ([`~PretrainedConfig.from_pretrained`]). Each key of `kwargs` that\n",
      "                  corresponds to a configuration attribute will be used to override said attribute with the\n",
      "                  supplied `kwargs` value. Remaining keys that do not correspond to any configuration attribute\n",
      "                  will be passed to the underlying model's `__init__` function.\n",
      "    \n",
      "    <Tip>\n",
      "    \n",
      "    Activate the special [\"offline-mode\"](https://huggingface.co/transformers/installation.html#offline-mode) to\n",
      "    use this method in a firewalled environment.\n",
      "    \n",
      "    </Tip>\n",
      "    \n",
      "    Examples:\n",
      "    \n",
      "    ```python\n",
      "    >>> from transformers import BertConfig, BertModel\n",
      "    \n",
      "    >>> # Download model and configuration from huggingface.co and cache.\n",
      "    >>> model = BertModel.from_pretrained(\"google-bert/bert-base-uncased\")\n",
      "    >>> # Model was saved using *save_pretrained('./test/saved_model/')* (for example purposes, not runnable).\n",
      "    >>> model = BertModel.from_pretrained(\"./test/saved_model/\")\n",
      "    >>> # Update configuration during loading.\n",
      "    >>> model = BertModel.from_pretrained(\"google-bert/bert-base-uncased\", output_attentions=True)\n",
      "    >>> assert model.config.output_attentions == True\n",
      "    >>> # Loading from a TF checkpoint file instead of a PyTorch model (slower, for example purposes, not runnable).\n",
      "    >>> config = BertConfig.from_json_file(\"./tf_model/my_tf_model_config.json\")\n",
      "    >>> model = BertModel.from_pretrained(\"./tf_model/my_tf_checkpoint.ckpt.index\", from_tf=True, config=config)\n",
      "    >>> # Loading from a Flax checkpoint file instead of a PyTorch model (slower)\n",
      "    >>> model = BertModel.from_pretrained(\"google-bert/bert-base-uncased\", from_flax=True)\n",
      "    ```\n",
      "    \n",
      "    * `low_cpu_mem_usage` algorithm:\n",
      "    \n",
      "    This is an experimental function that loads the model using ~1x model size CPU memory\n",
      "    \n",
      "    Here is how it works:\n",
      "    \n",
      "    1. save which state_dict keys we have\n",
      "    2. drop state_dict before the model is created, since the latter takes 1x model size CPU memory\n",
      "    3. after the model has been instantiated switch to the meta device all params/buffers that\n",
      "    are going to be replaced from the loaded state_dict\n",
      "    4. load state_dict 2nd time\n",
      "    5. replace the params/buffers from the state_dict\n",
      "    \n",
      "    Currently, it can't handle deepspeed ZeRO stage 3 and ignores loading errors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(transformers.ConditionalDetrForObjectDetection.from_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8080b0-f90a-4658-b28c-b9705aedadec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
